# **Gradient desecent for linear regression**
Gradient descent is one of most used algorithm in Machine Learning.Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent.

# Example
![image](gradient.png)

Supoose we are at any point, and we want to minimize the cost function. Thus this can be achieve by taking derivative of cost function.
The slope of the tangent will give a direction in which the value is decreases. Thus this algorithm make steps down the function.
The size of each step is determine by the learning rate.

# **Gradient descent for linear regression**
In this model, gradient descent is used to calculating the theta vector(or parameter vector). Once the parameter vector is calculated using
training examples, we can predict the output of unknown input.
